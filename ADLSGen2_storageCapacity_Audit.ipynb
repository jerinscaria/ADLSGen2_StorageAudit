{"cells":[{"cell_type":"markdown","source":["###ADLS Gen2 storage capacity audit\nThis notebook calculates the storage size at folder level and persists results to a delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a659160-612c-42b6-ab47-475ce47474f8"}}},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom multiprocessing.pool import ThreadPool\nfrom multiprocessing import Value, Lock"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"530a2570-c3ab-4515-aad2-5ce3a2b70968"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Use locks to get the counts correctly in a multithread enviornment"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85f8fa47-ae1c-4621-9d9e-5e114f1537dc"}}},{"cell_type":"code","source":["counter_lock = Lock()\ndef fileIncrement():\n    with counter_lock:\n        fileCounter.value += 1\n    return fileCounter.value"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fefc75a-590b-4ccc-9374-527089a4dc63"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def getTableSizeIterator(path, FileSizeList):\n  tableFileList = dbutils.fs.ls(path)\n  if len(tableFileList) > 0:\n    cnt = fileIncrement()\n    print(\"paths: \", path, \"cnt:\", cnt, \"cntFiles: \", len(tableFileList))\n    tableFileDF = spark.createDataFrame(data = tableFileList, schema = [\"path\", \"name\",\"size\"])\n    FileSizeDF = tableFileDF.agg(count('*').alias('fileCount'),round((sum('size')/(1073741824)),3).alias('sizeGB'))\n    FileSizeDF = FileSizeDF.withColumn('timestamp',current_timestamp()).withColumn('path',lit(path))\n    FileSizeDF = FileSizeDF.select(\"path\",\"timestamp\",\"fileCount\",\"sizeGB\")\n    FileSizeTempList = FileSizeDF.collect()\n    FileSizeList += FileSizeTempList\n\n    dirDF = tableFileDF.select(\"path\").where(\"size = 0 and name not like '%.%' and name not like '%delta_log/' and name not like '%our=%' and name not like '%inute=%' and name not like '$_%' ESCAPE '$'\")\n    for path in dirDF.rdd.map(lambda line: \"|\".join([str(x) for x in line])).collect():\n      getTableSizeIterator(path, FileSizeList)\n\n  return FileSizeList"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d462d802-83c0-4092-a4b5-97854d56d343"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def getFolderSizePool(row):\n  print (\"getting size of: \", row.path)\n  fileCounter = Value('i',0) \n  FinalList = []\n  FinalList = getTableSizeIterator(row.path, FinalList)\n  FileSizeCheckDF = spark.createDataFrame(data = FinalList, schema = [\"path\",\"timestamp\",\"fileCount\",\"sizeGB\"]) \n  FileSizeCheckDF.write.mode(\"append\").format(\"delta\").saveAsTable(\"Lake_File_Details\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1b0b205-0ab3-4bb2-9029-3fb513f58d96"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["fileCounter = Value('i',0)\ntableFileList = dbutils.fs.ls(\"dbfs:/mnt/lake/bronze\")\n\n#multithreading to get the stats parallelly.\npool=ThreadPool(10)\npool.map(getFolderSizePool,tableFileList)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ab85f356-3611-412f-956c-42dd4cc8d12d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nselect substring_index(path,'/',5) as path\n  ,count(*),sum(fileCount) as fileCount\n  ,round(sum(sizeGB),2) as sizeGB \nfrom  Lake_File_Details \ngroup by 1\norder by 4 desc"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b216e103-7e3a-4584-97a4-d82f766bbeb2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ADLSGen2_storageCapacity_Audit","dashboards":[],"language":"python","widgets":{},"notebookOrigID":899125170201962}},"nbformat":4,"nbformat_minor":0}
